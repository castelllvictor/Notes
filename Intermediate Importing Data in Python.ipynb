{"cells":[{"source":"# Intermediate Importing Data in Python\nRun the hidden code cell below to import the data used in this course.","metadata":{},"id":"20c73b4c-626a-4674-b2ca-0f4c47f60628","cell_type":"markdown"},{"source":"## 1 Importing data from the Internet","metadata":{},"cell_type":"markdown","id":"00e71f57-80a5-40a4-a882-ae85c5003e64"},{"source":"# Importing the course packages\nimport json\nimport pandas as pd\n\n# Read the Twitter data\ntweets_data = []\ntweets_file = open(\"datasets/tweets.txt\", \"r\")\nfor line in tweets_file:\n    tweet = json.loads(line)\n    tweets_data.append(tweet)\ntweets_file.close()\n\n# Import the other two datasets\nwine = pd.read_csv(\"datasets/winequality-red.csv\", sep=\";\")\nlatitude = pd.read_excel(\"datasets/latitude.xls\")","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false,"source_hidden":false},"executionTime":28,"lastSuccessfullyExecutedCode":"# Importing the course packages\nimport json\nimport pandas as pd\n\n# Read the Twitter data\ntweets_data = []\ntweets_file = open(\"datasets/tweets.txt\", \"r\")\nfor line in tweets_file:\n    tweet = json.loads(line)\n    tweets_data.append(tweet)\ntweets_file.close()\n\n# Import the other two datasets\ndf = pd.read_csv(\"datasets/winequality-red.csv\", sep=\";\")\nxl = pd.read_excel(\"datasets/latitude.xls\")"},"id":"cc8f4fbc-8936-468a-b789-fe76aae1fc03","cell_type":"code","execution_count":8,"outputs":[]},{"source":"## Take Notes\n\nAdd notes about the concepts you've learned and code cells with code you want to keep.","metadata":{},"id":"47777ca5-c181-41a3-8eef-b305c567d99d","cell_type":"markdown"},{"source":"_Add your notes here_","metadata":{},"id":"52b56ad7-3afc-4aa5-9540-f45bf185f38c","cell_type":"markdown"},{"source":"# Add your code snippets here","metadata":{"executionTime":16,"lastSuccessfullyExecutedCode":"# Add your code snippets here"},"id":"fb5e8360-ad35-430d-a8d1-559df0c5baae","cell_type":"code","execution_count":3,"outputs":[]},{"source":"Código para importar datos en una url a un df local.","metadata":{},"cell_type":"markdown","id":"d50ebfed-d6b6-4323-9a0e-fc683aa9b22d"},{"source":"# Import package\nfrom urllib.request import urlretrieve\n\n# Import pandas\nimport pandas as pd\n\n# Assign url of file: url\nurl = 'https://assets.datacamp.com/production/course_1606/datasets/winequality-red.csv'\n\n# Save file locally\nurlretrieve(url, 'winequality-red.csv')\n\n# Read file into a DataFrame and print its head\ndf = pd.read_csv('winequality-red.csv', sep=';')\nprint(df.head())","metadata":{},"cell_type":"code","id":"7e48e107-1e7f-4ee7-a606-4c6e72f11592","outputs":[],"execution_count":null},{"source":"Código para abrir y leer directamente de la web","metadata":{},"cell_type":"markdown","id":"2fd40629-9463-41ad-a219-f9e4a500b842"},{"source":"# Import packages\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\n# Assign url of file: url\nurl = 'https://assets.datacamp.com/production/course_1606/datasets/winequality-red.csv'\n\n# Read file into a DataFrame: df\ndf = pd.read_csv(url, sep=';')\n\n# Print the head of the DataFrame\nprint(df.head())\n\n# Plot first column of df\ndf.iloc[:, 0].hist()\nplt.xlabel('fixed acidity (g(tartaric acid)/dm$^3$)')\nplt.ylabel('count')\nplt.show()\n","metadata":{},"cell_type":"code","id":"7573ca99-3016-4032-a06f-9b6d2bbfd233","outputs":[],"execution_count":null},{"source":"Importar 'non-flat' de la web ","metadata":{},"cell_type":"markdown","id":"95e82da0-eb1f-4b16-9ad2-7c7154eb19ba"},{"source":"# Import package\nimport pandas as pd\n\n# Assign url of file: url\nurl = 'https://assets.datacamp.com/course/importing_data_into_r/latitude.xls'\n\n# Read in all sheets of Excel file: xls\nxls = pd.read_excel(url, sheet_name=None)\n\n# Print the sheetnames to the shell\nprint(xls.keys())\n\n# Print the head of the first sheet (using its name, NOT its index)\nprint(xls['1700'].head())\n","metadata":{},"cell_type":"code","id":"53e03a85-f2a5-45d6-8a35-d39aec27a9c7","outputs":[],"execution_count":null},{"source":"Hacer request de HTTP desde Python","metadata":{},"cell_type":"markdown","id":"4e6db2a7-b80d-4d32-a7d3-342f9a26cfac"},{"source":"# Import packages\nfrom urllib.request import urlopen, Request \n\n# Specify the url\nurl = \"https://campus.datacamp.com/courses/1606/4135?ex=2\"\n\n# This packages the request: request\nrequest = Request(url)\n\n# Sends the request and catches the response: response\nresponse = urlopen(request)\n\n# Print the datatype of response\nprint(type(response))\n\n# Be polite and close the response!\nresponse.close()\n","metadata":{},"cell_type":"code","id":"1d32802d-4632-4740-930d-b65cec27394c","outputs":[],"execution_count":null},{"source":"Imprimir los resultados optenidos del request","metadata":{},"cell_type":"markdown","id":"1abf7203-6c83-4c9b-afba-0a9d38c90af1"},{"source":"# Import packages\nfrom urllib.request import urlopen, Request\n\n# Specify the url\nurl = \"https://campus.datacamp.com/courses/1606/4135?ex=2\"\n\n# This packages the request\nrequest = Request(url)\n\n# Sends the request and catches the response: response\nresponse = urlopen(request)\n\n# Extract the response: html\nhtml = response.read()\n\n# Print the html\nprint(html) \n\n# Be polite and close the response!\nresponse.close()","metadata":{},"cell_type":"code","id":"4968011e-b15b-48ee-8242-feadf9066238","outputs":[],"execution_count":null},{"source":"Hacer requests con la libreria requests","metadata":{},"cell_type":"markdown","id":"52cec81d-b755-45d1-8c97-b8b55515ec21"},{"source":"# Import package\nimport requests \n\n# Specify the url: url\nurl = \"http://www.datacamp.com/teach/documentation\"\n\n# Packages the request, send the request and catch the response: r\nr = requests.get(url)\n\n# Extract the response: text\ntext = r.text\n\n# Print the html\nprint(text)","metadata":{},"cell_type":"code","id":"a5ccd68f-42c3-4180-94e9-816d561a51e3","outputs":[],"execution_count":null},{"source":"Parsing HTML with BeautifulSoup","metadata":{},"cell_type":"markdown","id":"db866e35-e5d6-45d1-9abd-fd61fe715586"},{"source":"# Import packages\nimport requests\nfrom bs4 import BeautifulSoup\n\n# Specify url: url\nurl = 'https://www.python.org/~guido/'\n\n# Package the request, send the request and catch the response: r\nr = requests.get(url)\n\n# Extracts the response as html: html_doc\nhtml_doc = r.text\n\n# Create a BeautifulSoup object from the HTML: soup\nsoup = BeautifulSoup(html_doc)\n\n# Prettify the BeautifulSoup object: pretty_soup\npretty_soup = soup.prettify()\n\n# Print the response\nprint(pretty_soup)","metadata":{},"cell_type":"code","id":"5a000f1d-1ac9-4f7d-9feb-3cdd7fdc7adc","outputs":[],"execution_count":null},{"source":"Turning a webpage into data using BeautifulSoup: getting the text","metadata":{},"cell_type":"markdown","id":"b38d904c-35cb-48c1-b6ca-ebdf21d92346"},{"source":"# Import packages\nimport requests\nfrom bs4 import BeautifulSoup\n\n# Specify url: url\nurl = 'https://www.python.org/~guido/'\n\n# Package the request, send the request and catch the response: r\nr = requests.get(url)\n\n# Extract the response as html: html_doc\nhtml_doc = r.text\n\n# Create a BeautifulSoup object from the HTML: soup\nsoup = BeautifulSoup(html_doc)\n\n# Get the title of Guido's webpage: guido_title\nguido_title = soup.title\n\n# Print the title of Guido's webpage to the shell\nprint(guido_title)\n\n# Get Guido's text: guido_text\nguido_text = soup.get_text()\n\n# Print Guido's text to the shell\nprint(guido_text)","metadata":{},"cell_type":"code","id":"60c66c9f-2210-41b7-8ad3-ca942a2e3c99","outputs":[],"execution_count":null},{"source":"Turning a webpage into data using BeautifulSoup: getting the hyperlinks","metadata":{},"cell_type":"markdown","id":"fe2017ef-85f6-4912-b438-f684d1a07d85"},{"source":"# Import packages\nimport requests\nfrom bs4 import BeautifulSoup\n\n# Specify url\nurl = 'https://www.python.org/~guido/'\n\n# Package the request, send the request and catch the response: r\nr = requests.get(url)\n\n# Extracts the response as html: html_doc\nhtml_doc = r.text\n\n# create a BeautifulSoup object from the HTML: soup\nsoup = BeautifulSoup(html_doc)\n\n# Print the title of Guido's webpage\nprint(soup.title)\n\n# Find all 'a' tags (which define hyperlinks): a_tags\na_tags = soup.find_all('a')\n\n# Print the URLs to the shell\nfor link in a_tags:\n    print(link.get('href'))","metadata":{},"cell_type":"code","id":"e2c2f4ce-b76b-4b4f-93b8-3cb31006ab25","outputs":[],"execution_count":null},{"source":"## Interacting with APIs to import data from the web","metadata":{},"cell_type":"markdown","id":"05b0f0fc-689f-43a3-b27b-990434bbfe84"},{"source":"Loading and exploring a JSON","metadata":{},"cell_type":"markdown","id":"be441490-d6ed-47ee-86ac-93f8ea45b1d1"},{"source":"# Load JSON: json_data\nwith open(\"a_movie.json\") as json_file:\n    json_data = json.load(json_file)\n\n# Print each key-value pair in json_data\nfor k in json_data.keys():\n    print(k + ': ', json_data[k])","metadata":{},"cell_type":"code","id":"695269e0-b995-49cb-9ce9-addd2576894a","outputs":[],"execution_count":null},{"source":"API requests","metadata":{},"cell_type":"markdown","id":"349ef482-a6c7-4454-9748-a4a42d824123"},{"source":"# Import requests package\nimport requests \n\n# Assign URL to variable: url\nurl = 'http://www.omdbapi.com/?apikey=72bc447a&t=the+social+network'\n\n# Package the request, send the request and catch the response: r\nr = requests.get(url)\n\n# Print the text of the response\nprint(r.text)\n","metadata":{},"cell_type":"code","id":"115c9e4e-97a4-4823-bdb7-850509c0cb30","outputs":[],"execution_count":null},{"source":"JSON–from the web to Python","metadata":{},"cell_type":"markdown","id":"deed7705-df95-4913-ad33-f9845dbe4746"},{"source":"# Import package\nimport requests\n\n# Assign URL to variable: url\nurl = 'http://www.omdbapi.com/?apikey=72bc447a&t=social+network'\n\n# Package the request, send the request and catch the response: r\nr = requests.get(url)\n\n# Decode the JSON data into a dictionary: json_data\njson_data = r.json()\n\n# Print each key-value pair in json_data\nfor k in json_data.keys():\n    print(k + ': ', json_data[k])\n","metadata":{},"cell_type":"code","id":"05e14b56-d1e7-48ba-9a96-6e07e97fba7d","outputs":[],"execution_count":null},{"source":"Checking out the Wikipedia API","metadata":{},"cell_type":"markdown","id":"94c13fba-73fc-4726-b8bc-f952fe17bce7"},{"source":"# Import package\nimport requests\n\n# Assign URL to variable: url\nurl ='https://en.wikipedia.org/w/api.php?action=query&prop=extracts&format=json&exintro=&titles=pizza'\n\n# Package the request, send the request and catch the response: r\nr = requests.get(url)\n\n# Decode the JSON data into a dictionary: json_data\njson_data = r.json()\n\n# Print the Wikipedia page extract\npizza_extract = json_data['query']['pages']['24768']['extract']\nprint(pizza_extract)\n","metadata":{},"cell_type":"code","id":"643b7136-7da6-4b3e-b23d-b6845f36c4c2","outputs":[],"execution_count":null},{"source":"## Diving deep into the Twitter API","metadata":{},"cell_type":"markdown","id":"3c75da8b-ff2c-4786-ad67-3cf5847cf466"},{"source":"Streaming tweets","metadata":{},"cell_type":"markdown","id":"dff32381-9c2c-4839-84f5-669f59d0d4a5"},{"source":"# Store credentials in relevant variables\nconsumer_key = \"nZ6EA0FxZ293SxGNg8g8aP0HM\"\nconsumer_secret = \"fJGEodwe3KiKUnsYJC3VRndj7jevVvXbK2D5EiJ2nehafRgA6i\"\naccess_token = \"1092294848-aHN7DcRP9B4VMTQIhwqOYiB14YkW92fFO8k8EPy\"\naccess_token_secret = \"X4dHmhPfaksHcQ7SCbmZa2oYBBVSD2g8uIHXsp5CTaksx\"\n\n# Create your Stream object with credentials\nstream = tweepy.Stream(consumer_key, consumer_secret, access_token, access_token_secret)\n\n# Filter your Stream variable\nstream.filter(track=[\"clinton\", \"trump\", \"sanders\", \"cruz\"])","metadata":{},"cell_type":"code","id":"df322c52-dffb-4653-8072-90870a00af44","outputs":[],"execution_count":null},{"source":"Load and explore your Twitter data","metadata":{},"cell_type":"markdown","id":"718fd9cc-9ba1-49e2-96d6-b6f572339e06"},{"source":"# Import package\nimport json\n\n# String of path to file: tweets_data_path\ntweets_data_path = 'tweets.txt'\n\n# Initialize empty list to store tweets: tweets_data\ntweets_data = []\n\n# Open connection to file\ntweets_file = open(tweets_data_path, \"r\")\n\n# Read in tweets and store in list: tweets_data\nfor line in tweets_file:\n    tweet = json.loads(line)\n    tweets_data.append(tweet)\n\n# Close connection to file\ntweets_file.close()\n\n# Print the keys of the first tweet dict\nprint(tweets_data[0].keys())\n","metadata":{},"cell_type":"code","id":"c388fe6c-1b9d-43c2-bb33-4fd3fe77c3d0","outputs":[],"execution_count":null},{"source":"Twitter data to DataFrame","metadata":{},"cell_type":"markdown","id":"3553a413-af05-43c8-90d6-f87c6ba7db8d"},{"source":"# Import package\nimport pandas as pd\n\n# Build DataFrame of tweet texts and languages\ndf = pd.DataFrame(tweets_data, columns=['text', 'lang'])\n\n# Print head of DataFrame\nprint(df.head())\n","metadata":{},"cell_type":"code","id":"ecee2431-377b-43e6-9c94-04373260b588","outputs":[],"execution_count":null},{"source":"A little bit of Twitter text analysis","metadata":{},"cell_type":"markdown","id":"5aaf16fd-f071-4e81-9a6d-4b10235bb802"},{"source":"# Initialize list to store tweet counts\n[clinton, trump, sanders, cruz] = [0, 0, 0, 0]\n\n# Iterate through df, counting the number of tweets in which\n# each candidate is mentioned\nfor index, row in df.iterrows():\n    clinton += word_in_text('clinton', row['text'])\n    trump += word_in_text('trump', row['text'])\n    sanders += word_in_text('sanders', row['text'])\n    cruz += word_in_text('cruz', row['text'])\n","metadata":{},"cell_type":"code","id":"498290bb-608f-4dfd-858d-234097f3d106","outputs":[],"execution_count":null},{"source":"Plotting your Twitter data","metadata":{},"cell_type":"markdown","id":"f64918d5-5825-464e-a1b8-8a5bbfac27d0"},{"source":"# Import packages\nimport matplotlib.pyplot as plt \nimport seaborn as sns \n\n# Set seaborn style\nsns.set(color_codes=True)\n\n# Create a list of labels:cd\ncd = ['clinton', 'trump', 'sanders', 'cruz']\n\n# Plot the bar chart\nax = sns.barplot(cd, [clinton, trump, sanders, cruz])\nax.set(ylabel=\"count\")\nplt.show()\n","metadata":{},"cell_type":"code","id":"d23b9083-fdfd-4d06-b1d9-ea79e0c0218a","outputs":[],"execution_count":null}],"metadata":{"language_info":{"name":"python","version":"3.8.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"editor":"DataCamp Workspace"},"nbformat":4,"nbformat_minor":5}